{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only performed one random step every time \n",
    "In this part we are going to use evolution strategies to optimize our models.\n",
    "Evolution strategies often use multiple samples to compare different mutations.\n",
    "These mutations are compared, selected or graded in a certain way.\n",
    "\n",
    "We are going to train the same linear regression model on the Boston houses dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(42)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.average(np.square(y_true - y_pred))\n",
    "\n",
    "def log_reg(weights, bias):\n",
    "    y_pred = X.dot(weights) + bias\n",
    "    return -mse(y, y_pred)\n",
    "\n",
    "npop = 512 # population size\n",
    "sigma = 0.5 # noise standard deviation\n",
    "lr = 1.0 # learning rate\n",
    "\n",
    "W = np.zeros(X.shape[1])\n",
    "b = np.array([0])\n",
    "\n",
    "W_moment = np.zeros(X.shape[1])\n",
    "b_moment = np.array([0.0])\n",
    "\n",
    "lr_decay = 0.995\n",
    "\n",
    "num_iters = 1000\n",
    "\n",
    "loss_history = []\n",
    "R_start = log_reg(W, b)\n",
    "for i in range(num_iters):\n",
    "    # initialize memory for a population of w's, and their rewards\n",
    "    N_W = np.random.randn(npop, W.shape[0])\n",
    "    N_b = np.random.randn(npop, 1) # samples from a normal distribution N(0,1)\n",
    "    R = np.zeros(npop)\n",
    "    for j in range(npop):\n",
    "        W_try = W + sigma * N_W[j]\n",
    "        b_try = b + sigma * N_b[j] \n",
    "        R[j] = log_reg(W_try, b_try)\n",
    "\n",
    "    R_max = np.argmax(R)\n",
    "    best_W = N_W[R_max]\n",
    "    best_b = N_b[R_max]\n",
    "\n",
    "    W_2 = best_W * lr\n",
    "    b_2 = best_b * lr\n",
    "\n",
    "    if log_reg(W + W_2, b + b_2) >= R_start:\n",
    "        W = W + W_2\n",
    "        b = b + b_2\n",
    "    R_start = log_reg(W, b)\n",
    "\n",
    "    loss_history.append(R_start)\n",
    "    lr *= lr_decay\n",
    "\n",
    "loss_line, = plt.plot(-np.array(loss_history), label='loss')\n",
    "plt.legend(handles=[loss_line])\n",
    "plt.show()\n",
    "print(\"loss: \", -loss_history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://blog.openai.com/evolution-strategies/\n",
    "\n",
    "https://gist.github.com/karpathy/77fbb6a8dac5395f1b73e7a89300318d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
